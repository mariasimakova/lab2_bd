{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "<h1>Lab 2: Document Stores</h1>\n",
    "\n",
    "<i>\n",
    "\n",
    "Course: 23D020 Big Data Management for Data Science <br>\n",
    "\n",
    "Author(s): Maria Simakova, Moritz Peist<br>\n",
    "\n",
    "**Group: L2-T05**<br>\n",
    "\n",
    "Programme: DSDM\n",
    "\n",
    "<hr>\n",
    "\n",
    "Note: This is a hands-on lab on Document Stores. We will be using one of the most popular document databases: MongoDB. We will practice how to import, create and model document databases, as well as how to query them.\n",
    "\n",
    "</i>\n",
    "\n",
    "</center>\n",
    "\n",
    "<hr>\n",
    "\n",
    "This notebook contains the comprehensive code and thus our solutions to the second lab. It can be run sequentially without errors, two execute all tasks in order.\n",
    "\n",
    "**Note**, in order to use this notebook effectively, the user needs to create a `.env` file in the same directory as this notebook in order to connect to MongoDB. The `.env` file should have the following content structure:\n",
    "\n",
    "```bash\n",
    "CONNECTION_STRING=<connection_string>\n",
    "DB_NAME=<database_name>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import datetime\n",
    "from pymongo import MongoClient\n",
    "from faker import Faker\n",
    "from time import perf_counter  # More accurate than time.time()\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lab2models:\n",
    "    \"\"\"\n",
    "    A class for managing and operating on MongoDB database models.\n",
    "\n",
    "    This class handles the creation of test data for different MongoDB data models,\n",
    "    establishes connections to MongoDB, and provides methods for data generation\n",
    "    and collection management.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_companies : int\n",
    "        Number of company documents to generate\n",
    "    connection_string : str\n",
    "        MongoDB connection string\n",
    "    db_name : str\n",
    "        Name of the MongoDB database to use\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_companies : int\n",
    "        Number of companies to generate\n",
    "    connection_string : str\n",
    "        MongoDB connection string\n",
    "    db_name : str\n",
    "        MongoDB database name\n",
    "    client : MongoClient\n",
    "        MongoDB client instance\n",
    "    db : Database\n",
    "        MongoDB database instance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_companies,\n",
    "        connection_string,\n",
    "        db_name,\n",
    "        faker=None,\n",
    "        random_generator=None,\n",
    "    ):\n",
    "        # Set random seed for reproducibility\n",
    "        Faker.seed(42)  # same people\n",
    "        random.seed(42)  # for generating the same number of employees per company\n",
    "        # Faker instance for generating fake data\n",
    "        self.faker = faker or Faker([\"es_ES\"])\n",
    "        self.random_generator = random_generator or random\n",
    "        # Initialize the number of companies, employees will be generated accordingly\n",
    "        self.num_companies = num_companies\n",
    "        # MongoDB connection string and database name\n",
    "        self.connection_string = connection_string\n",
    "        self.db_name = db_name\n",
    "        # Initialize MongoDB client and database\n",
    "        self.client = None\n",
    "        self.db = None\n",
    "\n",
    "    def connect_to_mongo(self) -> None:\n",
    "        \"\"\"\n",
    "        Connect to MongoDB using the provided connection string.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Connect to MongoDB\n",
    "        try:\n",
    "            self.client = MongoClient(self.connection_string)\n",
    "            self.db = self.client[self.db_name]\n",
    "            print(\"✅ Connected to MongoDB\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error connecting to MongoDB: {e}\\n\")\n",
    "\n",
    "    def list_collections(self) -> list:\n",
    "        \"\"\"\n",
    "        List all collections in the MongoDB database.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of collection names in the database\n",
    "        \"\"\"\n",
    "        # Make sure we're connected first\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "\n",
    "        # List all collections in the database\n",
    "        collections = self.db.list_collection_names()\n",
    "        # print(f\"Collections in {self.db_name}: {collections}\\n\")\n",
    "        return collections\n",
    "\n",
    "    def delete_collections(self) -> None:\n",
    "        \"\"\"\n",
    "        Delete all model collections from the database.\n",
    "\n",
    "        This method ensures we start with a clean database by removing\n",
    "        all existing collections related to the models.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Make sure we're connected first\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "\n",
    "        collections = self.db.list_collection_names()\n",
    "        # Drop collections if they exist\n",
    "        print(f\"Deleting collections: {collections}\")\n",
    "        [self.db.drop_collection(collection) for collection in collections]\n",
    "\n",
    "        # Now drop the collections\n",
    "        # self.db.drop_collection(\"m1_people\")\n",
    "        # self.db.drop_collection(\"m1_companies\")\n",
    "        # self.db.drop_collection(\"m2_people\")\n",
    "        # self.db.drop_collection(\"m3_companies\")\n",
    "\n",
    "    ######################################################################## B1+2 ########################################################################\n",
    "    def data_generator(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Generate test data for three different data models in MongoDB.\n",
    "\n",
    "        This method orchestrates the entire data generation process by:\n",
    "        1. Connecting to MongoDB and preparing collections\n",
    "        2. Generating company and people data\n",
    "        3. Storing data according to three different data models:\n",
    "        - Model 1: Normalized model with people referencing companies\n",
    "        - Model 2: Embedded model with companies embedded in people documents\n",
    "        - Model 3: Embedded model with people embedded in company documents\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing (number of companies, total number of employees)\n",
    "        \"\"\"\n",
    "        # Initialize database and collections\n",
    "        self._prepare_database()\n",
    "\n",
    "        # Generate data\n",
    "        company_data = self._generate_companies()\n",
    "        company_ids, person_data = self._generate_people(company_data)\n",
    "        total_employees = sum(len(persons) for _, persons in person_data.items())\n",
    "\n",
    "        # Insert data into different models\n",
    "        self._insert_model1_data(company_ids, person_data)\n",
    "        self._insert_model2_data(company_data, person_data)\n",
    "        self._insert_model3_data(company_data, person_data)\n",
    "\n",
    "        return self.num_companies, total_employees\n",
    "\n",
    "    def _prepare_database(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Connect to MongoDB and prepare collections for data insertion.\n",
    "\n",
    "        This method connects to MongoDB, deletes existing collections,\n",
    "        and creates new collections for all three data models.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing the four collection objects\n",
    "        \"\"\"\n",
    "        # Connect to MongoDB\n",
    "        self.connect_to_mongo()\n",
    "        # Delete collection data if exists from all of the 3 models\n",
    "        self.delete_collections()\n",
    "        # Create and obtain collections\n",
    "        m1_people = self.db.create_collection(\"m1_people\")\n",
    "        m1_companies = self.db.create_collection(\"m1_companies\")\n",
    "        m2_people = self.db.create_collection(\"m2_people\")\n",
    "        m3_companies = self.db.create_collection(\"m3_companies\")\n",
    "\n",
    "        self.collections = {\n",
    "            \"m1_people\": m1_people,\n",
    "            \"m1_companies\": m1_companies,\n",
    "            \"m2_people\": m2_people,\n",
    "            \"m3_companies\": m3_companies,\n",
    "        }\n",
    "\n",
    "        return self.collections\n",
    "\n",
    "    def _generate_companies(self) -> list:\n",
    "        \"\"\"\n",
    "        Generate company data for the specified number of companies.\n",
    "\n",
    "        Uses Faker to create realistic company information including\n",
    "        name, domain, email, URL, and VAT number.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of dictionaries containing company data\n",
    "        \"\"\"\n",
    "        # Set up faker\n",
    "        fake = self.faker\n",
    "        # Generate company data\n",
    "        company_data = []\n",
    "        for _ in range(self.num_companies):\n",
    "            company_name = fake.company()\n",
    "            domain = fake.domain_name()\n",
    "            company = {\n",
    "                \"domain\": domain,\n",
    "                \"email\": f\"info@{domain}\",\n",
    "                \"name\": company_name,\n",
    "                \"url\": f\"www.{domain}\",\n",
    "                \"vatNumber\": fake.bothify(text=\"??######\"),\n",
    "            }\n",
    "            company_data.append(company)\n",
    "\n",
    "        return company_data\n",
    "\n",
    "    def _generate_people(self, company_data: list) -> tuple:\n",
    "        \"\"\"\n",
    "        Generate employee data for each company.\n",
    "\n",
    "        Creates a random number of employees for each company with\n",
    "        realistic personal information including name, email, age, etc.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        company_data : list\n",
    "            List of company dictionaries generated by _generate_companies\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing (company MongoDB IDs, dictionary mapping\n",
    "            company indices to lists of person data)\n",
    "        \"\"\"\n",
    "        fake = self.faker\n",
    "        # Insert companies for Model 1 and get their IDs\n",
    "        company_ids = (\n",
    "            self.collections[\"m1_companies\"].insert_many(company_data).inserted_ids\n",
    "        )\n",
    "\n",
    "        # Generate random number of employees per company\n",
    "        employees_per_company = [\n",
    "            self.random_generator.randint(25, 50) for _ in range(self.num_companies)\n",
    "        ]\n",
    "\n",
    "        # Organize people by company\n",
    "        person_data = {company_idx: [] for company_idx in range(self.num_companies)}\n",
    "\n",
    "        # For each company, generate the specific number of employees\n",
    "        for company_idx in range(self.num_companies):\n",
    "            for _ in range(employees_per_company[company_idx]):\n",
    "                if fake.random_element(elements=(True, False)):\n",
    "                    first_name = fake.first_name_male()\n",
    "                    sex = \"M\"\n",
    "                else:\n",
    "                    first_name = fake.first_name_female()\n",
    "                    sex = \"F\"\n",
    "\n",
    "                last_name = fake.last_name()\n",
    "                full_name = f\"{first_name} {last_name}\"\n",
    "                birth_date = fake.date_of_birth(minimum_age=20, maximum_age=65)\n",
    "                birth_datetime = datetime.datetime.combine(birth_date, datetime.time())\n",
    "                age = (datetime.datetime.now().date() - birth_date).days // 365\n",
    "\n",
    "                username_full = f\"{first_name.lower()}.{last_name.lower()}\".replace(\n",
    "                    \" \", \"\"\n",
    "                )\n",
    "                username_short = f\"{first_name.lower()[0]}{last_name.lower()}\".replace(\n",
    "                    \" \", \"\"\n",
    "                )\n",
    "\n",
    "                person = {\n",
    "                    \"age\": age,\n",
    "                    \"companyEmail\": f\"{username_full}@{company_data[company_idx]['domain']}\",\n",
    "                    \"dateOfBirth\": birth_datetime,\n",
    "                    \"email\": f\"{username_short}@{fake.free_email_domain()}\",\n",
    "                    \"firstName\": first_name,\n",
    "                    \"fullName\": full_name,\n",
    "                    \"sex\": sex,\n",
    "                }\n",
    "                person_data[company_idx].append(person)\n",
    "\n",
    "        return company_ids, person_data\n",
    "\n",
    "    def _insert_model1_data(self, company_ids: list, person_data: dict) -> None:\n",
    "        \"\"\"\n",
    "        Insert data using Model 1: Normalized model with people referencing companies.\n",
    "\n",
    "        In this model, people documents contain a reference to their company.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        company_ids : list\n",
    "            List of MongoDB ObjectIDs for the companies\n",
    "        person_data : dict\n",
    "            Dictionary mapping company indices to lists of person data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        m1_people = self.collections[\"m1_people\"]\n",
    "        for company_idx, persons in tqdm(\n",
    "            person_data.items(), desc=\"Inserting data into Model 1: \"\n",
    "        ):\n",
    "            for person in persons:\n",
    "                m1_person = person.copy()\n",
    "                m1_person[\"worksIn\"] = company_ids[company_idx]  # Reference to company\n",
    "                m1_people.insert_one(m1_person)\n",
    "\n",
    "    def _insert_model2_data(self, company_data: list, person_data: dict) -> None:\n",
    "        \"\"\"\n",
    "        Insert data using Model 2: Embedded model with companies embedded in people documents.\n",
    "\n",
    "        In this model, each person document contains the full company document.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        company_data : list\n",
    "            List of company dictionaries\n",
    "        person_data : dict\n",
    "            Dictionary mapping company indices to lists of person data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        m2_people = self.collections[\"m2_people\"]\n",
    "        for company_idx, persons in tqdm(\n",
    "            person_data.items(), desc=\"Inserting data into Model 2: \"\n",
    "        ):\n",
    "            for person in persons:\n",
    "                m2_person = person.copy()\n",
    "                m2_person[\"worksIn\"] = company_data[\n",
    "                    company_idx\n",
    "                ]  # Embed company document\n",
    "                m2_people.insert_one(m2_person)\n",
    "\n",
    "    def _insert_model3_data(self, company_data: list, person_data: dict) -> None:\n",
    "        \"\"\"\n",
    "        Insert data using Model 3: Embedded model with people embedded in company documents.\n",
    "\n",
    "        In this model, each company document contains a list of all its employees.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        company_data : list\n",
    "            List of company dictionaries\n",
    "        person_data : dict\n",
    "            Dictionary mapping company indices to lists of person data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        m3_companies = self.collections[\"m3_companies\"]\n",
    "        for company_idx, company in enumerate(\n",
    "            tqdm(company_data, desc=\"Inserting data into Model 3: \")\n",
    "        ):\n",
    "            m3_company = company.copy()\n",
    "            m3_company[\"staff\"] = person_data.get(company_idx, [])\n",
    "            m3_companies.insert_one(m3_company)\n",
    "\n",
    "    ######################################################################## B4 ########################################################################\n",
    "    def run_query(self, collection: str, pipeline: list, model_name: str) -> float:\n",
    "        \"\"\"\n",
    "        Execute a MongoDB aggregation query and measure its performance.\n",
    "\n",
    "        This method runs an aggregation pipeline against the specified collection,\n",
    "        measures the execution time, and prints the results.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        collection : str\n",
    "            The name of the MongoDB collection to query\n",
    "        pipeline : list\n",
    "            MongoDB aggregation pipeline to execute\n",
    "        model_name : str\n",
    "            Name of the model being queried (for display purposes)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Execution time of the query in seconds\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The method prints the first 3 results and shows the total count of results\n",
    "        along with the query execution time.\n",
    "        \"\"\"\n",
    "        # Make sure we're connected first\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "        print(f\"\\n# {model_name}\")\n",
    "        start_time = perf_counter()\n",
    "        results = list(self.db[collection].aggregate(pipeline))\n",
    "        end_time = perf_counter()\n",
    "        query_time = end_time - start_time\n",
    "        # show the first 3 results\n",
    "        for i, result in enumerate(results[:3]):\n",
    "            print(result)\n",
    "        if len(results) > 3:\n",
    "            print(f\"... and {len(results) - 3} other results\")\n",
    "\n",
    "        print(f\"Time taken: {query_time:.4f} seconds\")\n",
    "\n",
    "        return query_time\n",
    "\n",
    "    def run_update_query(\n",
    "        self,\n",
    "        collection: str,\n",
    "        filter_query: dict,\n",
    "        update_query: dict,\n",
    "        array_filters: list,\n",
    "        model_name: str,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Execute a MongoDB update operation and measure its performance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        collection_name : str\n",
    "            The name of the MongoDB collection to update\n",
    "        filter_query : dict\n",
    "            MongoDB filter to select documents to update\n",
    "        update_query : dict\n",
    "            MongoDB update operation to apply\n",
    "        model_name : str\n",
    "            Name of the model being updated (for display purposes)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Execution time of the update in seconds\n",
    "        \"\"\"\n",
    "        # Make sure we're connected\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "\n",
    "        print(f\"\\n# {model_name}\")\n",
    "\n",
    "        # Start timing\n",
    "        start_time = perf_counter()\n",
    "\n",
    "        # Perform the update\n",
    "        result = self.db[collection].update_many(\n",
    "            filter_query, update_query, array_filters=array_filters\n",
    "        )\n",
    "\n",
    "        # End timing\n",
    "        end_time = perf_counter()\n",
    "        query_time = end_time - start_time\n",
    "\n",
    "        print(f\"Updated {result.modified_count} documents\")\n",
    "        print(f\"Time taken: {query_time:.4f} seconds\")\n",
    "\n",
    "        return query_time\n",
    "\n",
    "    def run_batch(\n",
    "        self, models: list[dict[str, list, str]], is_update: bool = False\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"\n",
    "        Run a batch of aggregation or update queries on MongoDB and measure performance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        models : list\n",
    "            List of model configurations (dicts with name, pipeline, collection)\n",
    "        is_update : bool\n",
    "            Flag to indicate if the queries are update operations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Execution times for each query\n",
    "        \"\"\"\n",
    "        # Connect if needed\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "\n",
    "        # Execute queries with dictionary comprehension\n",
    "        if is_update:\n",
    "            results = {\n",
    "                model[\"name\"]: self.run_update_query(\n",
    "                    collection=model[\"collection\"],\n",
    "                    filter_query=model[\"filter\"],\n",
    "                    update_query=model[\"update\"],\n",
    "                    array_filters=model[\"array_filters\"],\n",
    "                    model_name=model[\"name\"],\n",
    "                )\n",
    "                for model in models\n",
    "            }\n",
    "        else:\n",
    "            results = {\n",
    "                model[\"name\"]: self.run_query(\n",
    "                    collection=model[\"collection\"],\n",
    "                    pipeline=model[\"pipeline\"],\n",
    "                    model_name=model[\"name\"],\n",
    "                )\n",
    "                for model in models\n",
    "            }\n",
    "\n",
    "        # Find fastest model in one operation\n",
    "        fastest_model = min(results, key=results.get)\n",
    "        fastest_time = results[fastest_model]\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\n{30 * '='} Model comparison: {30 * '='}\")\n",
    "\n",
    "        for name, t in results.items():\n",
    "            print(f\"{name}: {t:.4}s\")\n",
    "\n",
    "        print(f\"The fastest model is {fastest_model} with: {fastest_time:.4}s\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def close_connection(self):\n",
    "        \"\"\"\n",
    "        Close the MongoDB connection.\n",
    "        \"\"\"\n",
    "        if self.client:\n",
    "            self.client.close()\n",
    "            print(\"✅ MongoDB connection closed\")\n",
    "        else:\n",
    "            print(\"❌ No MongoDB connection to close\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# The .env file should be in the same directory as this notebook, with the following content:\n",
    "\"\"\"\n",
    "CONNECTION_STRING=<connection_string>\n",
    "DB_NAME=<database_name>\n",
    "\"\"\"\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Load MongoDB connection string from environment variables\n",
    "connection_string = dotenv.get_key(\n",
    "    \".env\", \"CONNECTION_STRING\"\n",
    ")  # Usually: \"mongodb://localhost:27017/\"\n",
    "\n",
    "# Load MongoDB database name from environment variables\n",
    "db_name = dotenv.get_key(\".env\", \"DB_NAME\")  # Some database name, e.g. \"lab2\"\n",
    "\n",
    "# Setup parameters - shouldn't be hardcoded as per the instructions\n",
    "# connection_string = \"mongodb://localhost:27017/\"\n",
    "# db_name = \"lab2\"\n",
    "num_companies = 50000\n",
    "\n",
    "# Create an instance of the Lab2models class\n",
    "lab = Lab2models(\n",
    "    num_companies=num_companies, connection_string=connection_string, db_name=db_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2. Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MongoDB\n",
      "\n",
      "Deleting collections: ['m2_people', 'm3_companies', 'm1_people', 'm1_companies']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0ef1fd1e984086933428d8d3386ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inserting data into Model 1:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4602f734eb4d2e98c5dd76562518f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inserting data into Model 2:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c154041dc6544dcfa33943ad61cf7116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inserting data into Model 3:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of documents: 500 companies and 18523 people\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "num_companies, actual_people = lab.data_generator()\n",
    "\n",
    "# Print the number of documents in each collection\n",
    "print(\n",
    "    f\"Actual number of documents: {num_companies} companies and {actual_people} people\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3. Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: For each person, retrieve their full name and their company’s name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_1 = [\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"m1_companies\",\n",
    "            \"localField\": \"worksIn\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"companyName\",\n",
    "        }\n",
    "    },\n",
    "    {\"$unwind\": \"$companyName\"},\n",
    "    {\"$project\": {\"_id\": 0, \"fullName\": 1, \"companyName\": \"$companyName.name\"}},\n",
    "]\n",
    "\n",
    "q1_2 = [{\"$project\": {\"_id\": 0, \"fullName\": 1, \"companyName\": \"$worksIn.name\"}}]\n",
    "\n",
    "q1_3 = [\n",
    "    {\"$unwind\": \"$staff\"},\n",
    "    {\"$project\": {\"_id\": 0, \"fullName\": \"$staff.fullName\", \"companyName\": \"$name\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_q1 = [\n",
    "    {\n",
    "        \"name\": \"Model 1\",\n",
    "        \"collection\": \"m1_people\",\n",
    "        \"pipeline\": q1_1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2\",\n",
    "        \"collection\": \"m2_people\",\n",
    "        \"pipeline\": q1_2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3\",\n",
    "        \"collection\": \"m3_companies\",\n",
    "        \"pipeline\": q1_3,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model 1\n",
      "{'fullName': 'Lola Reyes', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Adriana Palomino', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Nidia Saldaña', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "... and 18520 other results\n",
      "Time taken: 0.3162 seconds\n",
      "\n",
      "# Model 2\n",
      "{'fullName': 'Lola Reyes', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Adriana Palomino', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Nidia Saldaña', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "... and 18520 other results\n",
      "Time taken: 0.0261 seconds\n",
      "\n",
      "# Model 3\n",
      "{'fullName': 'Lola Reyes', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Adriana Palomino', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Nidia Saldaña', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "... and 18520 other results\n",
      "Time taken: 0.0209 seconds\n",
      "\n",
      "============================== Model comparison: ==============================\n",
      "Model 1: 0.3162s\n",
      "Model 2: 0.02614s\n",
      "Model 3: 0.02091s\n",
      "The fastest model is Model 3 with: 0.02091s\n"
     ]
    }
   ],
   "source": [
    "q1_res = lab.run_batch(queries_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: For each company, retrieve its name and the number of employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_1 = [\n",
    "    {\"$group\": {\"_id\": \"$worksIn\", \"employeeCount\": {\"$sum\": 1}}},\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"m1_companies\",\n",
    "            \"localField\": \"_id\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"companyName\",\n",
    "        }\n",
    "    },\n",
    "    {\"$unwind\": \"$companyName\"},\n",
    "    {\"$project\": {\"_id\": 0, \"companyName\": \"$companyName.name\", \"employeeCount\": 1}},\n",
    "]  # for the order of the output, first company then number of employees\n",
    "\n",
    "q2_2 = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$worksIn._id\",\n",
    "            \"companyName\": {\"$first\": \"$worksIn.name\"},\n",
    "            \"employeeCount\": {\"$sum\": 1},\n",
    "        }\n",
    "    },\n",
    "    {\"$project\": {\"_id\": 0, \"companyName\": 1, \"employeeCount\": 1}},\n",
    "]\n",
    "\n",
    "q2_3 = [\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"companyName\": \"$name\",\n",
    "            \"employeeCount\": {\"$size\": \"$staff\"},\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_q2 = [\n",
    "    {\n",
    "        \"name\": \"Model 1\",\n",
    "        \"collection\": \"m1_people\",\n",
    "        \"pipeline\": q2_1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2\",\n",
    "        \"collection\": \"m2_people\",\n",
    "        \"pipeline\": q2_2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3\",\n",
    "        \"collection\": \"m3_companies\",\n",
    "        \"pipeline\": q2_3,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model 1\n",
      "{'employeeCount': 33, 'companyName': 'Distribuciones Díez S.A.'}\n",
      "{'employeeCount': 45, 'companyName': 'Tovar y Cisneros S.Coop.'}\n",
      "{'employeeCount': 47, 'companyName': 'Transportes Roda y asociados S.L.'}\n",
      "... and 497 other results\n",
      "Time taken: 0.0158 seconds\n",
      "\n",
      "# Model 2\n",
      "{'companyName': 'Transportes Roda y asociados S.L.', 'employeeCount': 47}\n",
      "{'companyName': 'Tovar y Cisneros S.Coop.', 'employeeCount': 45}\n",
      "{'companyName': 'Distribuciones Díez S.A.', 'employeeCount': 33}\n",
      "... and 497 other results\n",
      "Time taken: 0.0099 seconds\n",
      "\n",
      "# Model 3\n",
      "{'companyName': 'Banca Privada OLMJ S.L.N.E', 'employeeCount': 25}\n",
      "{'companyName': 'Grupo Rocamora S.Com.', 'employeeCount': 48}\n",
      "{'companyName': 'Restauración CR S.Coop.', 'employeeCount': 33}\n",
      "... and 497 other results\n",
      "Time taken: 0.0033 seconds\n",
      "\n",
      "============================== Model comparison: ==============================\n",
      "Model 1: 0.01584s\n",
      "Model 2: 0.009854s\n",
      "Model 3: 0.003259s\n",
      "The fastest model is Model 3 with: 0.003259s\n"
     ]
    }
   ],
   "source": [
    "q2_res = lab.run_batch(queries_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: For each person born before 1988, update their age to “30”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 params\n",
    "q3_1_filter = {\"dateOfBirth\": {\"$lt\": datetime.datetime(1988, 1, 1)}}\n",
    "q3_1_update = {\"$set\": {\"age\": \"30\"}}\n",
    "# Model 2 params\n",
    "q3_2_filter = {\"dateOfBirth\": {\"$lt\": datetime.datetime(1988, 1, 1)}}\n",
    "q3_2_update = {\"$set\": {\"age\": \"30\"}}\n",
    "# Model 3 params -- To update ALL matching staff members and not only the first one, we need to use arrayFilters\n",
    "q3_3_filter = {\n",
    "    \"staff\": {\"$elemMatch\": {\"dateOfBirth\": {\"$lt\": datetime.datetime(1988, 1, 1)}}}\n",
    "}\n",
    "q3_3_update = {\"$set\": {\"staff.$[elem].age\": \"30\"}}\n",
    "q3_3_array_filters = [{\"elem.dateOfBirth\": {\"$lt\": datetime.datetime(1988, 1, 1)}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_q3 = [\n",
    "    {\n",
    "        \"name\": \"Model 1\",\n",
    "        \"collection\": \"m1_people\",\n",
    "        \"filter\": q3_1_filter,\n",
    "        \"update\": q3_1_update,\n",
    "        \"array_filters\": None,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2\",\n",
    "        \"collection\": \"m2_people\",\n",
    "        \"filter\": q3_2_filter,\n",
    "        \"update\": q3_2_update,\n",
    "        \"array_filters\": None,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3\",\n",
    "        \"collection\": \"m3_companies\",\n",
    "        \"filter\": q3_3_filter,\n",
    "        \"update\": q3_3_update,\n",
    "        \"array_filters\": q3_3_array_filters,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model 1\n",
      "Updated 11463 documents\n",
      "Time taken: 0.1001 seconds\n",
      "\n",
      "# Model 2\n",
      "Updated 11463 documents\n",
      "Time taken: 0.0749 seconds\n",
      "\n",
      "# Model 3\n",
      "Updated 500 documents\n",
      "Time taken: 0.0199 seconds\n",
      "\n",
      "============================== Model comparison: ==============================\n",
      "Model 1: 0.1001s\n",
      "Model 2: 0.07486s\n",
      "Model 3: 0.0199s\n",
      "The fastest model is Model 3 with: 0.0199s\n"
     ]
    }
   ],
   "source": [
    "q3_res = lab.run_batch(queries_q3, is_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: For each company, update its name to include the word “Company”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 params\n",
    "q4_1_filter = {}\n",
    "q4_1_update = [{\"$set\": {\"name\": {\"$concat\": [\"$name\", \" Company\"]}}}]\n",
    "\n",
    "# Model 2 params\n",
    "q4_2_filter = {}\n",
    "q4_2_update = [{\"$set\": {\"worksIn.name\": {\"$concat\": [\"$worksIn.name\", \" Company\"]}}}]\n",
    "\n",
    "# Model 3 params\n",
    "q4_3_filter = {}\n",
    "q4_3_update = [{\"$set\": {\"name\": {\"$concat\": [\"$name\", \" Company\"]}}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_q4 = [\n",
    "    {\n",
    "        \"name\": \"Model 1\",\n",
    "        \"collection\": \"m1_companies\",  \n",
    "        \"filter\": q4_1_filter,\n",
    "        \"update\": q4_1_update,\n",
    "        \"array_filters\": None\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2\",\n",
    "        \"collection\": \"m2_people\",\n",
    "        \"filter\": q4_2_filter,\n",
    "        \"update\": q4_2_update,\n",
    "        \"array_filters\": None\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3\",\n",
    "        \"collection\": \"m3_companies\",\n",
    "        \"filter\": q4_3_filter,\n",
    "        \"update\": q4_3_update,\n",
    "        \"array_filters\": None\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model 1\n",
      "Updated 500 documents\n",
      "Time taken: 0.0071 seconds\n",
      "\n",
      "# Model 2\n",
      "Updated 18523 documents\n",
      "Time taken: 0.1429 seconds\n",
      "\n",
      "# Model 3\n",
      "Updated 500 documents\n",
      "Time taken: 0.0132 seconds\n",
      "\n",
      "============================== Model comparison: ==============================\n",
      "Model 1: 0.007077s\n",
      "Model 2: 0.1429s\n",
      "Model 3: 0.01325s\n",
      "The fastest model is Model 1 with: 0.007077s\n"
     ]
    }
   ],
   "source": [
    "res_q4 = lab.run_batch(queries_q4, is_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MongoDB connection closed\n"
     ]
    }
   ],
   "source": [
    "# Finally close the connection\n",
    "lab.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Performance Comparison\n",
    "\n",
    "The following code, is just small helper code to turn our model results automatically into LaTex format for automated synchronization with the submission document through Overleaf.\n",
    "\n",
    "Furthermore, it highlights which model performed best for which task in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all results to a DataFrame\n",
    "results = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"M1\": [\n",
    "            q1_res[\"Model 1\"],\n",
    "            q2_res[\"Model 1\"],\n",
    "            q3_res[\"Model 1\"],\n",
    "            # res_q4[\"Model 1\"],\n",
    "        ],\n",
    "        \"M2\": [\n",
    "            q1_res[\"Model 2\"],\n",
    "            q2_res[\"Model 2\"],\n",
    "            q3_res[\"Model 2\"],\n",
    "            # res_q4[\"Model 2\"],\n",
    "        ],\n",
    "        \"M3\": [\n",
    "            q1_res[\"Model 3\"],\n",
    "            q2_res[\"Model 3\"],\n",
    "            q3_res[\"Model 3\"],\n",
    "            # res_q4[\"Model 3\"],\n",
    "        ],\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"Q1\", \"Q2\", \"Q3\"],  # , \"Q4\"],\n",
    ").style.format(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to LaTeX and write to file\n",
    "with open(r\"results/model_comparison.tex\", \"w\") as f:\n",
    "    f.write(\n",
    "        results.to_latex(\n",
    "            caption=\"Query Execution Times per Model (in seconds)\",\n",
    "            label=\"tab:model_comparison\",\n",
    "            position=\"H\",\n",
    "            position_float=\"centering\",\n",
    "            hrules=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a253e_row2_col0, #T_a253e_row2_col1, #T_a253e_row2_col2 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a253e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a253e_level0_col0\" class=\"col_heading level0 col0\" >Q1</th>\n",
       "      <th id=\"T_a253e_level0_col1\" class=\"col_heading level0 col1\" >Q2</th>\n",
       "      <th id=\"T_a253e_level0_col2\" class=\"col_heading level0 col2\" >Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a253e_level0_row0\" class=\"row_heading level0 row0\" >M1</th>\n",
       "      <td id=\"T_a253e_row0_col0\" class=\"data row0 col0\" >0.3162</td>\n",
       "      <td id=\"T_a253e_row0_col1\" class=\"data row0 col1\" >0.0158</td>\n",
       "      <td id=\"T_a253e_row0_col2\" class=\"data row0 col2\" >0.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a253e_level0_row1\" class=\"row_heading level0 row1\" >M2</th>\n",
       "      <td id=\"T_a253e_row1_col0\" class=\"data row1 col0\" >0.0261</td>\n",
       "      <td id=\"T_a253e_row1_col1\" class=\"data row1 col1\" >0.0099</td>\n",
       "      <td id=\"T_a253e_row1_col2\" class=\"data row1 col2\" >0.0749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a253e_level0_row2\" class=\"row_heading level0 row2\" >M3</th>\n",
       "      <td id=\"T_a253e_row2_col0\" class=\"data row2 col0\" >0.0209</td>\n",
       "      <td id=\"T_a253e_row2_col1\" class=\"data row2 col1\" >0.0033</td>\n",
       "      <td id=\"T_a253e_row2_col2\" class=\"data row2 col2\" >0.0199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10b5d7c50>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.highlight_min(color=\"green\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
