{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "<h1>Lab 2: Document Stores</h1>\n",
    "\n",
    "<i>\n",
    "\n",
    "Course: 23D020 Big Data Management for Data Science <br>\n",
    "\n",
    "Author(s): Maria Simakova, Moritz Peist<br>\n",
    "\n",
    "**Group: L2-T05**<br>\n",
    "\n",
    "Programme: DSDM\n",
    "\n",
    "<hr>\n",
    "\n",
    "Note: This is a hands-on lab on Document Stores. We will be using one of the most popular document databases: MongoDB. We will practice how to import, create and model document databases, as well as how to query them.\n",
    "\n",
    "</i>\n",
    "\n",
    "</center>\n",
    "\n",
    "<hr>\n",
    "\n",
    "This notebook contains the comprehensive code and thus our solutions to the second lab. It can be run sequentially without errors, two execute all tasks in order.\n",
    "\n",
    "**Note**, in order to use this notebook effectively, the user needs to create a `.env` file in the same directory as this notebook in order to connect to MongoDB. The `.env` file should have the following content structure:\n",
    "\n",
    "```bash\n",
    "CONNECTION_STRING=<connection_string>\n",
    "DB_NAME=<database_name>\n",
    "```\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Implementation Pipeline\n",
    "\n",
    "This code implements the following pipeline:\n",
    "\n",
    "1. **Setup & Connection**: Initialize MongoDB connection parameters and setup the environment\n",
    "2. **Data Generation**: Create synthetic data for companies and persons using Faker\n",
    "3. **Data Modeling & Insertion**: \n",
    "   - Model 1: Two separate collections with references between them\n",
    "   - Model 2: Person documents with embedded company data\n",
    "   - Model 3: Company documents with embedded person data\n",
    "4. **Query Implementation**: Implement the four required queries for each model\n",
    "   - Q1: Retrieve person names with their company names\n",
    "   - Q2: Retrieve company names with employee counts\n",
    "   - Q3: Update age for people born before 1988\n",
    "   - Q4: Update company names to include \"Company\" suffix\n",
    "5. **Performance Measurement**: Measure and compare execution times across models\n",
    "6. **Results Analysis**: Export results and analyze performance differences\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import datetime\n",
    "from pymongo import MongoClient\n",
    "from faker import Faker\n",
    "from time import perf_counter  # More accurate than time.time()\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1. Data Generation (PIPELINE STEP 1-2: Setup and Data Generation)\n",
    "The Lab2models class handles both the data generation and the data modeling implementation.It provides methods for connecting to MongoDB, creating test data, and implementing the three different data models required for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lab2models:\n",
    "    \"\"\"\n",
    "    A class for managing and operating on MongoDB database models.\n",
    "\n",
    "    This class handles the creation of test data for different MongoDB data models,\n",
    "    establishes connections to MongoDB, and provides methods for data generation\n",
    "    and collection management.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_companies : int\n",
    "        Number of company documents to generate\n",
    "    connection_string : str\n",
    "        MongoDB connection string\n",
    "    db_name : str\n",
    "        Name of the MongoDB database to use\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_companies : int\n",
    "        Number of companies to generate\n",
    "    connection_string : str\n",
    "        MongoDB connection string\n",
    "    db_name : str\n",
    "        MongoDB database name\n",
    "    client : MongoClient\n",
    "        MongoDB client instance\n",
    "    db : Database\n",
    "        MongoDB database instance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_companies,\n",
    "        connection_string,\n",
    "        db_name,\n",
    "        faker=None,\n",
    "        random_generator=None,\n",
    "    ):\n",
    "        # Set random seed for reproducibility\n",
    "        Faker.seed(42)  # same people\n",
    "        random.seed(42)  # for generating the same number of employees per company\n",
    "        # Faker instance for generating fake data\n",
    "        self.faker = faker or Faker([\"es_ES\"])\n",
    "        self.random_generator = random_generator or random\n",
    "        # Initialize the number of companies, employees will be generated accordingly\n",
    "        self.num_companies = num_companies\n",
    "        # MongoDB connection string and database name\n",
    "        self.connection_string = connection_string\n",
    "        self.db_name = db_name\n",
    "        # Initialize MongoDB client and database\n",
    "        self.client = None\n",
    "        self.db = None\n",
    "\n",
    "    def connect_to_mongo(self) -> None:\n",
    "        \"\"\"\n",
    "        Connect to MongoDB using the provided connection string.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Connect to MongoDB\n",
    "        try:\n",
    "            self.client = MongoClient(self.connection_string)\n",
    "            self.db = self.client[self.db_name]\n",
    "            print(\"✅ Connected to MongoDB\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error connecting to MongoDB: {e}\\n\")\n",
    "\n",
    "    def list_collections(self) -> list:\n",
    "        \"\"\"\n",
    "        List all collections in the MongoDB database.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of collection names in the database\n",
    "        \"\"\"\n",
    "        # Make sure we're connected first\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "\n",
    "        # List all collections in the database\n",
    "        collections = self.db.list_collection_names()\n",
    "        # print(f\"Collections in {self.db_name}: {collections}\\n\")\n",
    "        return collections\n",
    "\n",
    "    def delete_collections(self) -> None:\n",
    "        \"\"\"\n",
    "        Delete all model collections from the database.\n",
    "\n",
    "        This method ensures we start with a clean database by removing\n",
    "        all existing collections related to the models.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Make sure we're connected first\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "\n",
    "        collections = self.db.list_collection_names()\n",
    "        # Drop collections if they exist\n",
    "        print(f\"Deleting collections: {collections}\")\n",
    "        [self.db.drop_collection(collection) for collection in collections]\n",
    "\n",
    "        # Now drop the collections\n",
    "        # self.db.drop_collection(\"m1_people\")\n",
    "        # self.db.drop_collection(\"m1_companies\")\n",
    "        # self.db.drop_collection(\"m2_people\")\n",
    "        # self.db.drop_collection(\"m3_companies\")\n",
    "\n",
    "    ######################################################################## B1+2 ########################################################################\n",
    "    def data_generator(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Generate test data for three different data models in MongoDB.\n",
    "\n",
    "        This method orchestrates the entire data generation process by:\n",
    "        1. Connecting to MongoDB and preparing collections\n",
    "        2. Generating company and people data\n",
    "        3. Storing data according to three different data models:\n",
    "        - Model 1: Normalized model with people referencing companies\n",
    "        - Model 2: Embedded model with companies embedded in people documents\n",
    "        - Model 3: Embedded model with people embedded in company documents\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing (number of companies, total number of employees)\n",
    "        \"\"\"\n",
    "        # Initialize database and collections\n",
    "        self._prepare_database()\n",
    "\n",
    "        # Generate data\n",
    "        company_data = self._generate_companies()\n",
    "        company_ids, person_data = self._generate_people(company_data)\n",
    "        total_employees = sum(len(persons) for _, persons in person_data.items())\n",
    "\n",
    "        # Insert data into different models\n",
    "        self._insert_model1_data(company_ids, person_data)\n",
    "        self._insert_model2_data(company_data, person_data)\n",
    "        self._insert_model3_data(company_data, person_data)\n",
    "\n",
    "        return self.num_companies, total_employees\n",
    "\n",
    "    def _prepare_database(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Connect to MongoDB and prepare collections for data insertion.\n",
    "\n",
    "        This method connects to MongoDB, deletes existing collections,\n",
    "        and creates new collections for all three data models.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing the four collection objects\n",
    "        \"\"\"\n",
    "        # Connect to MongoDB\n",
    "        self.connect_to_mongo()\n",
    "        # Delete collection data if exists from all of the 3 models\n",
    "        self.delete_collections()\n",
    "        # Create and obtain collections\n",
    "        m1_people = self.db.create_collection(\"m1_people\")\n",
    "        m1_companies = self.db.create_collection(\"m1_companies\")\n",
    "        m2_people = self.db.create_collection(\"m2_people\")\n",
    "        m3_companies = self.db.create_collection(\"m3_companies\")\n",
    "\n",
    "        self.collections = {\n",
    "            \"m1_people\": m1_people,\n",
    "            \"m1_companies\": m1_companies,\n",
    "            \"m2_people\": m2_people,\n",
    "            \"m3_companies\": m3_companies,\n",
    "        }\n",
    "\n",
    "        return self.collections\n",
    "\n",
    "    def _generate_companies(self) -> list:\n",
    "        \"\"\"\n",
    "        Generate company data for the specified number of companies.\n",
    "\n",
    "        Uses Faker to create realistic company information including\n",
    "        name, domain, email, URL, and VAT number.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of dictionaries containing company data\n",
    "        \"\"\"\n",
    "        # Set up faker\n",
    "        fake = self.faker\n",
    "        # Generate company data\n",
    "        company_data = []\n",
    "        for _ in range(self.num_companies):\n",
    "            company_name = fake.company()\n",
    "            domain = fake.domain_name()\n",
    "            company = {\n",
    "                \"domain\": domain,\n",
    "                \"email\": f\"info@{domain}\",\n",
    "                \"name\": company_name,\n",
    "                \"url\": f\"www.{domain}\",\n",
    "                \"vatNumber\": fake.bothify(text=\"??######\"),\n",
    "            }\n",
    "            company_data.append(company)\n",
    "\n",
    "        return company_data\n",
    "\n",
    "    def _generate_people(self, company_data: list) -> tuple:\n",
    "        \"\"\"\n",
    "        Generate employee data for each company.\n",
    "\n",
    "        Creates a random number of employees for each company with\n",
    "        realistic personal information including name, email, age, etc.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        company_data : list\n",
    "            List of company dictionaries generated by _generate_companies\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing (company MongoDB IDs, dictionary mapping\n",
    "            company indices to lists of person data)\n",
    "        \"\"\"\n",
    "        fake = self.faker\n",
    "        # Insert companies for Model 1 and get their IDs\n",
    "        company_ids = (\n",
    "            self.collections[\"m1_companies\"].insert_many(company_data).inserted_ids\n",
    "        )\n",
    "\n",
    "        # Generate random number of employees per company\n",
    "        employees_per_company = [\n",
    "            self.random_generator.randint(25, 50) for _ in range(self.num_companies)\n",
    "        ]\n",
    "\n",
    "        # Organize people by company\n",
    "        person_data = {company_idx: [] for company_idx in range(self.num_companies)}\n",
    "\n",
    "        # For each company, generate the specific number of employees\n",
    "        for company_idx in range(self.num_companies):\n",
    "            for _ in range(employees_per_company[company_idx]):\n",
    "                if fake.random_element(elements=(True, False)):\n",
    "                    first_name = fake.first_name_male()\n",
    "                    sex = \"M\"\n",
    "                else:\n",
    "                    first_name = fake.first_name_female()\n",
    "                    sex = \"F\"\n",
    "\n",
    "                last_name = fake.last_name()\n",
    "                full_name = f\"{first_name} {last_name}\"\n",
    "                birth_date = fake.date_of_birth(minimum_age=20, maximum_age=65)\n",
    "                birth_datetime = datetime.datetime.combine(birth_date, datetime.time())\n",
    "                age = (datetime.datetime.now().date() - birth_date).days // 365\n",
    "\n",
    "                username_full = f\"{first_name.lower()}.{last_name.lower()}\".replace(\n",
    "                    \" \", \"\"\n",
    "                )\n",
    "                username_short = f\"{first_name.lower()[0]}{last_name.lower()}\".replace(\n",
    "                    \" \", \"\"\n",
    "                )\n",
    "\n",
    "                person = {\n",
    "                    \"age\": age,\n",
    "                    \"companyEmail\": f\"{username_full}@{company_data[company_idx]['domain']}\",\n",
    "                    \"dateOfBirth\": birth_datetime,\n",
    "                    \"email\": f\"{username_short}@{fake.free_email_domain()}\",\n",
    "                    \"firstName\": first_name,\n",
    "                    \"fullName\": full_name,\n",
    "                    \"sex\": sex,\n",
    "                }\n",
    "                person_data[company_idx].append(person)\n",
    "\n",
    "        return company_ids, person_data\n",
    "\n",
    "    def _insert_model1_data(self, company_ids: list, person_data: dict) -> None:\n",
    "        \"\"\"\n",
    "        Insert data using Model 1: Normalized model with people referencing companies.\n",
    "\n",
    "        In this model, people documents contain a reference to their company.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        company_ids : list\n",
    "            List of MongoDB ObjectIDs for the companies\n",
    "        person_data : dict\n",
    "            Dictionary mapping company indices to lists of person data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        m1_people = self.collections[\"m1_people\"]\n",
    "\n",
    "        # Create a list for collecting all documents before insertion\n",
    "        all_documents = []\n",
    "\n",
    "        # Prepare all documents first\n",
    "        for company_idx, persons in tqdm(\n",
    "            person_data.items(), desc=\"Preparing documents for Model 1: \"\n",
    "        ):\n",
    "            for person in persons:\n",
    "                m1_person = person.copy()\n",
    "                m1_person[\"worksIn\"] = company_ids[company_idx]  # Reference to company\n",
    "                all_documents.append(m1_person)\n",
    "\n",
    "        # Insert all documents in a single operation\n",
    "        if all_documents:\n",
    "            print(f\"Inserting {len(all_documents)} documents into Model 1...\")\n",
    "            m1_people.insert_many(all_documents)\n",
    "\n",
    "    def _insert_model2_data(self, company_data: list, person_data: dict) -> None:\n",
    "        \"\"\"\n",
    "        Insert data using Model 2: Embedded model with companies embedded in people documents.\n",
    "\n",
    "        In this model, each person document contains the full company document.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        company_data : list\n",
    "            List of company dictionaries\n",
    "        person_data : dict\n",
    "            Dictionary mapping company indices to lists of person data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        m2_people = self.collections[\"m2_people\"]\n",
    "\n",
    "        # Create a list for collecting all documents before insertion\n",
    "        all_documents = []\n",
    "\n",
    "        for company_idx, persons in tqdm(\n",
    "            person_data.items(), desc=\"Preparing documents for Model 2: \"\n",
    "        ):\n",
    "            for person in persons:\n",
    "                m2_person = person.copy()\n",
    "                m2_person[\"worksIn\"] = company_data[\n",
    "                    company_idx\n",
    "                ]  # Embed company document\n",
    "                all_documents.append(m2_person)\n",
    "\n",
    "        # Insert all documents in a single operation\n",
    "        if all_documents:\n",
    "            print(f\"Inserting {len(all_documents)} documents into Model 2...\")\n",
    "            m2_people.insert_many(all_documents)\n",
    "\n",
    "    def _insert_model3_data(self, company_data: list, person_data: dict) -> None:\n",
    "        \"\"\"\n",
    "        Insert data using Model 3: Embedded model with people embedded in company documents.\n",
    "\n",
    "        In this model, each company document contains a list of all its employees.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        company_data : list\n",
    "            List of company dictionaries\n",
    "        person_data : dict\n",
    "            Dictionary mapping company indices to lists of person data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        m3_companies = self.collections[\"m3_companies\"]\n",
    "        # Create a list for collecting all documents before insertion\n",
    "        all_documents = []\n",
    "        for company_idx, company in enumerate(\n",
    "            tqdm(company_data, desc=\"Preparing documents for Model 3: \")\n",
    "        ):\n",
    "            m3_company = company.copy()\n",
    "            m3_company[\"staff\"] = person_data.get(company_idx, [])\n",
    "            # Add the company document to the list\n",
    "            all_documents.append(m3_company)\n",
    "        # Insert all documents in a single operation\n",
    "        if all_documents:\n",
    "            print(f\"Inserting {len(all_documents)} documents into Model 3...\")\n",
    "            m3_companies.insert_many(all_documents)\n",
    "\n",
    "    ######################################################################## B4 ########################################################################\n",
    "\n",
    "    def run_query(self, collection: str, pipeline: list, model_name: str) -> float:\n",
    "        \"\"\"\n",
    "        Execute a MongoDB aggregation query and measure its performance.\n",
    "\n",
    "        This method runs an aggregation pipeline against the specified collection,\n",
    "        measures the execution time, and prints the results.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        collection : str\n",
    "            The name of the MongoDB collection to query\n",
    "        pipeline : list\n",
    "            MongoDB aggregation pipeline to execute\n",
    "        model_name : str\n",
    "            Name of the model being queried (for display purposes)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Execution time of the query in seconds\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The method prints the first 3 results and shows the total count of results\n",
    "        along with the query execution time.\n",
    "        \"\"\"\n",
    "        # Make sure we're connected first\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "        print(f\"\\n# {model_name}\")\n",
    "        start_time = perf_counter()\n",
    "        results = list(self.db[collection].aggregate(pipeline))\n",
    "        end_time = perf_counter()\n",
    "        query_time = end_time - start_time\n",
    "        # show the first 3 results\n",
    "        for i, result in enumerate(results[:3]):\n",
    "            print(result)\n",
    "        if len(results) > 3:\n",
    "            print(f\"... and {len(results) - 3} other results\")\n",
    "\n",
    "        print(f\"Time taken: {query_time:.4f} seconds\")\n",
    "\n",
    "        return query_time\n",
    "\n",
    "    def run_update_query(\n",
    "        self,\n",
    "        collection: str,\n",
    "        filter_query: dict,\n",
    "        update_query: dict,\n",
    "        array_filters: list,\n",
    "        model_name: str,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Execute a MongoDB update operation and measure its performance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        collection_name : str\n",
    "            The name of the MongoDB collection to update\n",
    "        filter_query : dict\n",
    "            MongoDB filter to select documents to update\n",
    "        update_query : dict\n",
    "            MongoDB update operation to apply\n",
    "        model_name : str\n",
    "            Name of the model being updated (for display purposes)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Execution time of the update in seconds\n",
    "        \"\"\"\n",
    "        # Make sure we're connected\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "\n",
    "        print(f\"\\n# {model_name}\")\n",
    "\n",
    "        # Start timing\n",
    "        start_time = perf_counter()\n",
    "\n",
    "        # Perform the update\n",
    "        result = self.db[collection].update_many(\n",
    "            filter_query, update_query, array_filters=array_filters\n",
    "        )\n",
    "\n",
    "        # End timing\n",
    "        end_time = perf_counter()\n",
    "        query_time = end_time - start_time\n",
    "\n",
    "        print(f\"Updated {result.modified_count} documents\")\n",
    "        print(f\"Time taken: {query_time:.4f} seconds\")\n",
    "\n",
    "        return query_time\n",
    "\n",
    "    def run_batch(\n",
    "        self, models: list[dict[str, list, str]], is_update: bool = False\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"\n",
    "        Run a batch of aggregation or update queries on MongoDB and measure performance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        models : list\n",
    "            List of model configurations (dicts with name, pipeline, collection)\n",
    "        is_update : bool\n",
    "            Flag to indicate if the queries are update operations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Execution times for each query\n",
    "        \"\"\"\n",
    "        # Connect if needed\n",
    "        if self.db is None:\n",
    "            self.connect_to_mongo()\n",
    "\n",
    "        # Execute queries with dictionary comprehension\n",
    "        if is_update:\n",
    "            results = {\n",
    "                model[\"name\"]: self.run_update_query(\n",
    "                    collection=model[\"collection\"],\n",
    "                    filter_query=model[\"filter\"],\n",
    "                    update_query=model[\"update\"],\n",
    "                    array_filters=model[\"array_filters\"],\n",
    "                    model_name=model[\"name\"],\n",
    "                )\n",
    "                for model in models\n",
    "            }\n",
    "        else:\n",
    "            results = {\n",
    "                model[\"name\"]: self.run_query(\n",
    "                    collection=model[\"collection\"],\n",
    "                    pipeline=model[\"pipeline\"],\n",
    "                    model_name=model[\"name\"],\n",
    "                )\n",
    "                for model in models\n",
    "            }\n",
    "\n",
    "        # Find fastest model in one operation\n",
    "        fastest_model = min(results, key=results.get)\n",
    "        fastest_time = results[fastest_model]\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\n{30 * '='} Model comparison: {30 * '='}\")\n",
    "\n",
    "        for name, t in results.items():\n",
    "            print(f\"{name}: {t:.4}s\")\n",
    "\n",
    "        print(f\"The fastest model is {fastest_model} with: {fastest_time:.4}s\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def close_connection(self):\n",
    "        \"\"\"\n",
    "        Close the MongoDB connection.\n",
    "        \"\"\"\n",
    "        if self.client:\n",
    "            self.client.close()\n",
    "            print(\"✅ MongoDB connection closed\")\n",
    "        else:\n",
    "            print(\"❌ No MongoDB connection to close\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE STEP 1: Connection Setup\n",
    "Here we establish our connection to MongoDB and configure our database parameters. The `.env` file is used to avoid hardcoding credentials in the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# The .env file should be in the same directory as this notebook, with the following content:\n",
    "\"\"\"\n",
    "CONNECTION_STRING=<connection_string>\n",
    "DB_NAME=<database_name>\n",
    "\"\"\"\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Load MongoDB connection string from environment variables\n",
    "connection_string = dotenv.get_key(\n",
    "    \".env\", \"CONNECTION_STRING\"\n",
    ")  # Usually: \"mongodb://localhost:27017/\"\n",
    "\n",
    "# Load MongoDB database name from environment variables\n",
    "db_name = dotenv.get_key(\".env\", \"DB_NAME\")  # Some database name, e.g. \"lab2\"\n",
    "\n",
    "# Setup parameters - shouldn't be hardcoded as per the instructions\n",
    "# connection_string = \"mongodb://localhost:27017/\"\n",
    "# db_name = \"lab2\"\n",
    "num_companies = 50000\n",
    "\n",
    "# Create an instance of the Lab2models class\n",
    "lab = Lab2models(\n",
    "    num_companies=num_companies, connection_string=connection_string, db_name=db_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2. Data Insertion (PIPELINE STEP 3: Data Modeling & Insertion)\n",
    "Using the data_generator method, we create and insert data for all three models:\n",
    "- Model 1: Two separate collections with references (m1_people, m1_companies)\n",
    "- Model 2: Person documents with embedded company data (m2_people)\n",
    "- Model 3: Company documents with embedded person data (m3_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MongoDB\n",
      "\n",
      "Deleting collections: ['m3_companies', 'm1_people', 'm2_people', 'm1_companies']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad0278ace9a47338873bb689b37646c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing documents for Model 1:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 1877120 documents into Model 1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0743511af27457b9e2624866505b648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing documents for Model 2:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 1877120 documents into Model 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bcb71131fc456db5f8275e115e9b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing documents for Model 3:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 50000 documents into Model 3...\n",
      "Actual number of documents: 50000 companies and 1877120 people\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "num_companies, actual_people = lab.data_generator()\n",
    "\n",
    "# Print the number of documents in each collection\n",
    "print(\n",
    "    f\"Actual number of documents: {num_companies} companies and {actual_people} people\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3. Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: For each person, retrieve their full name and their company’s name. (PIPELINE STEP 4.1: Query Q1 Implementation)\n",
    "\n",
    ">Query 1: \"For each person, retrieve their full name and their company's name\"\n",
    "\n",
    "Implementation approach for each model:\n",
    "- M1: Use $lookup to join people with companies by reference\n",
    "- M2: Project directly from embedded company data\n",
    "- M3: Unwind the staff array and project from both collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_1 = [\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"m1_companies\",\n",
    "            \"localField\": \"worksIn\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"companyName\",\n",
    "        }\n",
    "    },\n",
    "    {\"$unwind\": \"$companyName\"},\n",
    "    {\"$project\": {\"_id\": 0, \"fullName\": 1, \"companyName\": \"$companyName.name\"}},\n",
    "]\n",
    "\n",
    "q1_2 = [{\"$project\": {\"_id\": 0, \"fullName\": 1, \"companyName\": \"$worksIn.name\"}}]\n",
    "\n",
    "q1_3 = [\n",
    "    {\"$unwind\": \"$staff\"},\n",
    "    {\"$project\": {\"_id\": 0, \"fullName\": \"$staff.fullName\", \"companyName\": \"$name\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_q1 = [\n",
    "    {\n",
    "        \"name\": \"Model 1\",\n",
    "        \"collection\": \"m1_people\",\n",
    "        \"pipeline\": q1_1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2\",\n",
    "        \"collection\": \"m2_people\",\n",
    "        \"pipeline\": q1_2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3\",\n",
    "        \"collection\": \"m3_companies\",\n",
    "        \"pipeline\": q1_3,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model 1\n",
      "{'fullName': 'Eusebio Ribas', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Ignacio Calvo', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Manola Cáceres', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "... and 1877117 other results\n",
      "Time taken: 114.7579 seconds\n",
      "\n",
      "# Model 2\n",
      "{'fullName': 'Eusebio Ribas', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Ignacio Calvo', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Manola Cáceres', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "... and 1877117 other results\n",
      "Time taken: 9.2571 seconds\n",
      "\n",
      "# Model 3\n",
      "{'fullName': 'Eusebio Ribas', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Ignacio Calvo', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "{'fullName': 'Manola Cáceres', 'companyName': 'Banca Privada OLMJ S.L.N.E'}\n",
      "... and 1877117 other results\n",
      "Time taken: 6.2107 seconds\n",
      "\n",
      "============================== Model comparison: ==============================\n",
      "Model 1: 114.8s\n",
      "Model 2: 9.257s\n",
      "Model 3: 6.211s\n",
      "The fastest model is Model 3 with: 6.211s\n"
     ]
    }
   ],
   "source": [
    "q1_res = lab.run_batch(queries_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: For each company, retrieve its name and the number of employees.(PIPELINE STEP 4.2: Query Q2 Implementation)\n",
    "\n",
    ">Query 2: \"For each company, retrieve its name and the number of employees\"\n",
    " \n",
    "Implementation approach for each model:\n",
    "- M1: Group by company ID, count people, then lookup company names\n",
    "- M2: Group by company ID, get first company name, count people\n",
    "- M3: Simply project company name and array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_1 = [\n",
    "    {\"$group\": {\"_id\": \"$worksIn\", \"employeeCount\": {\"$sum\": 1}}},\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"m1_companies\",\n",
    "            \"localField\": \"_id\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"companyName\",\n",
    "        }\n",
    "    },\n",
    "    {\"$unwind\": \"$companyName\"},\n",
    "    {\"$project\": {\"_id\": 0, \"companyName\": \"$companyName.name\", \"employeeCount\": 1}},\n",
    "]  # for the order of the output, first company then number of employees\n",
    "\n",
    "q2_2 = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$worksIn._id\",\n",
    "            \"companyName\": {\"$first\": \"$worksIn.name\"},\n",
    "            \"employeeCount\": {\"$sum\": 1},\n",
    "        }\n",
    "    },\n",
    "    {\"$project\": {\"_id\": 0, \"companyName\": 1, \"employeeCount\": 1}},\n",
    "]\n",
    "\n",
    "q2_3 = [\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"companyName\": \"$name\",\n",
    "            \"employeeCount\": {\"$size\": \"$staff\"},\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_q2 = [\n",
    "    {\n",
    "        \"name\": \"Model 1\",\n",
    "        \"collection\": \"m1_people\",\n",
    "        \"pipeline\": q2_1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2\",\n",
    "        \"collection\": \"m2_people\",\n",
    "        \"pipeline\": q2_2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3\",\n",
    "        \"collection\": \"m3_companies\",\n",
    "        \"pipeline\": q2_3,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model 1\n",
      "{'employeeCount': 29, 'companyName': 'Promociones Españolas S.C.P'}\n",
      "{'employeeCount': 42, 'companyName': 'Américo Mancebo Castells S.A.'}\n",
      "{'employeeCount': 33, 'companyName': 'Ignacia Corral Alberola S.L.L.'}\n",
      "... and 49997 other results\n",
      "Time taken: 5.5505 seconds\n",
      "\n",
      "# Model 2\n",
      "{'companyName': 'Construcción Moliner S.A.', 'employeeCount': 33}\n",
      "{'companyName': 'Familia Roma S.L.', 'employeeCount': 42}\n",
      "{'companyName': 'Hermanos Pujol S.L.U.', 'employeeCount': 42}\n",
      "... and 49997 other results\n",
      "Time taken: 2.6517 seconds\n",
      "\n",
      "# Model 3\n",
      "{'companyName': 'Banca Privada OLMJ S.L.N.E', 'employeeCount': 25}\n",
      "{'companyName': 'Grupo Rocamora S.Com.', 'employeeCount': 48}\n",
      "{'companyName': 'Restauración CR S.Coop.', 'employeeCount': 33}\n",
      "... and 49997 other results\n",
      "Time taken: 0.6222 seconds\n",
      "\n",
      "============================== Model comparison: ==============================\n",
      "Model 1: 5.55s\n",
      "Model 2: 2.652s\n",
      "Model 3: 0.6222s\n",
      "The fastest model is Model 3 with: 0.6222s\n"
     ]
    }
   ],
   "source": [
    "q2_res = lab.run_batch(queries_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: For each person born before 1988, update their age to “30”. (PIPELINE STEP 4.3: Query Q3 Implementation)\n",
    "\n",
    ">Query 3: \"For each person born before 1988, update their age to '30'\"\n",
    "\n",
    "Implementation approach for each model:\n",
    "- M1: Direct update on people documents\n",
    "- M2: Direct update on people documents\n",
    "- M3: Update embedded documents using array filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 params\n",
    "q3_1_filter = {\"dateOfBirth\": {\"$lt\": datetime.datetime(1988, 1, 1)}}\n",
    "q3_1_update = {\"$set\": {\"age\": \"30\"}}\n",
    "# Model 2 params\n",
    "q3_2_filter = {\"dateOfBirth\": {\"$lt\": datetime.datetime(1988, 1, 1)}}\n",
    "q3_2_update = {\"$set\": {\"age\": \"30\"}}\n",
    "# Model 3 params -- To update ALL matching staff members and not only the first one, we need to use arrayFilters\n",
    "q3_3_filter = {\n",
    "    \"staff\": {\"$elemMatch\": {\"dateOfBirth\": {\"$lt\": datetime.datetime(1988, 1, 1)}}}\n",
    "}\n",
    "q3_3_update = {\"$set\": {\"staff.$[elem].age\": \"30\"}}\n",
    "q3_3_array_filters = [{\"elem.dateOfBirth\": {\"$lt\": datetime.datetime(1988, 1, 1)}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_q3 = [\n",
    "    {\n",
    "        \"name\": \"Model 1\",\n",
    "        \"collection\": \"m1_people\",\n",
    "        \"filter\": q3_1_filter,\n",
    "        \"update\": q3_1_update,\n",
    "        \"array_filters\": None,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2\",\n",
    "        \"collection\": \"m2_people\",\n",
    "        \"filter\": q3_2_filter,\n",
    "        \"update\": q3_2_update,\n",
    "        \"array_filters\": None,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3\",\n",
    "        \"collection\": \"m3_companies\",\n",
    "        \"filter\": q3_3_filter,\n",
    "        \"update\": q3_3_update,\n",
    "        \"array_filters\": q3_3_array_filters,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model 1\n",
      "Updated 1168778 documents\n",
      "Time taken: 19.0553 seconds\n",
      "\n",
      "# Model 2\n",
      "Updated 1168778 documents\n",
      "Time taken: 20.9813 seconds\n",
      "\n",
      "# Model 3\n",
      "Updated 50000 documents\n",
      "Time taken: 9.4313 seconds\n",
      "\n",
      "============================== Model comparison: ==============================\n",
      "Model 1: 19.06s\n",
      "Model 2: 20.98s\n",
      "Model 3: 9.431s\n",
      "The fastest model is Model 3 with: 9.431s\n"
     ]
    }
   ],
   "source": [
    "q3_res = lab.run_batch(queries_q3, is_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: For each company, update its name to include the word “Company”. (PIPELINE STEP 4.4: Query Q4 Implementation)\n",
    "\n",
    ">Query 4: \"For each company, update its name to include the word 'Company'\"\n",
    "\n",
    "Implementation approach for each model:\n",
    "- M1: Update company documents directly\n",
    "- M2: Update embedded company data in all person documents\n",
    "- M3: Update company documents directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 params\n",
    "q4_1_filter = {}\n",
    "q4_1_update = [{\"$set\": {\"name\": {\"$concat\": [\"$name\", \" Company\"]}}}]\n",
    "\n",
    "# Model 2 params\n",
    "q4_2_filter = {}\n",
    "q4_2_update = [{\"$set\": {\"worksIn.name\": {\"$concat\": [\"$worksIn.name\", \" Company\"]}}}]\n",
    "\n",
    "# Model 3 params\n",
    "q4_3_filter = {}\n",
    "q4_3_update = [{\"$set\": {\"name\": {\"$concat\": [\"$name\", \" Company\"]}}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_q4 = [\n",
    "    {\n",
    "        \"name\": \"Model 1\",\n",
    "        \"collection\": \"m1_companies\",\n",
    "        \"filter\": q4_1_filter,\n",
    "        \"update\": q4_1_update,\n",
    "        \"array_filters\": None,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2\",\n",
    "        \"collection\": \"m2_people\",\n",
    "        \"filter\": q4_2_filter,\n",
    "        \"update\": q4_2_update,\n",
    "        \"array_filters\": None,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3\",\n",
    "        \"collection\": \"m3_companies\",\n",
    "        \"filter\": q4_3_filter,\n",
    "        \"update\": q4_3_update,\n",
    "        \"array_filters\": None,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 50000 documents\n",
      "Time taken: 1.0061 seconds\n",
      "\n",
      "# Model 2\n",
      "Updated 1877120 documents\n",
      "Time taken: 50.6679 seconds\n",
      "\n",
      "# Model 3\n",
      "Updated 50000 documents\n",
      "Time taken: 8.7810 seconds\n",
      "\n",
      "============================== Model comparison: ==============================\n",
      "Model 1: 1.006s\n",
      "Model 2: 50.67s\n",
      "Model 3: 8.781s\n",
      "The fastest model is Model 1 with: 1.006s\n"
     ]
    }
   ],
   "source": [
    "res_q4 = lab.run_batch(queries_q4, is_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MongoDB connection closed\n"
     ]
    }
   ],
   "source": [
    "# Finally close the connection\n",
    "lab.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Performance Comparison (PIPELINE STEP 5: Performance Analysis)\n",
    "\n",
    "Here we collect all timing results and analyze model performance across queries. We create a formatted DataFrame to visualize the results and export to LaTeX for inclusion in the final report.\n",
    "\n",
    "Tus, the following code, is just small helper code to turn our model results automatically into LaTex format for automated synchronization with the submission document through Overleaf.\n",
    "\n",
    "Furthermore, it highlights which model performed best for which task in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all results to a DataFrame\n",
    "results = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"M1\": [\n",
    "            q1_res[\"Model 1\"],\n",
    "            q2_res[\"Model 1\"],\n",
    "            q3_res[\"Model 1\"],\n",
    "            res_q4[\"Model 1\"],\n",
    "        ],\n",
    "        \"M2\": [\n",
    "            q1_res[\"Model 2\"],\n",
    "            q2_res[\"Model 2\"],\n",
    "            q3_res[\"Model 2\"],\n",
    "            res_q4[\"Model 2\"],\n",
    "        ],\n",
    "        \"M3\": [\n",
    "            q1_res[\"Model 3\"],\n",
    "            q2_res[\"Model 3\"],\n",
    "            q3_res[\"Model 3\"],\n",
    "            res_q4[\"Model 3\"],\n",
    "        ],\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    ").style.format(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to LaTeX and write to file\n",
    "with open(r\"results/model_comparison.tex\", \"w\") as f:\n",
    "    f.write(\n",
    "        results.to_latex(\n",
    "            caption=\"Query Execution Times per Model (in seconds)\",\n",
    "            label=\"tab:model_comparison\",\n",
    "            position=\"H\",\n",
    "            position_float=\"centering\",\n",
    "            hrules=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8a133_row0_col3, #T_8a133_row2_col0, #T_8a133_row2_col1, #T_8a133_row2_col2 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8a133\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8a133_level0_col0\" class=\"col_heading level0 col0\" >Q1</th>\n",
       "      <th id=\"T_8a133_level0_col1\" class=\"col_heading level0 col1\" >Q2</th>\n",
       "      <th id=\"T_8a133_level0_col2\" class=\"col_heading level0 col2\" >Q3</th>\n",
       "      <th id=\"T_8a133_level0_col3\" class=\"col_heading level0 col3\" >Q4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8a133_level0_row0\" class=\"row_heading level0 row0\" >M1</th>\n",
       "      <td id=\"T_8a133_row0_col0\" class=\"data row0 col0\" >114.7579</td>\n",
       "      <td id=\"T_8a133_row0_col1\" class=\"data row0 col1\" >5.5505</td>\n",
       "      <td id=\"T_8a133_row0_col2\" class=\"data row0 col2\" >19.0553</td>\n",
       "      <td id=\"T_8a133_row0_col3\" class=\"data row0 col3\" >1.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a133_level0_row1\" class=\"row_heading level0 row1\" >M2</th>\n",
       "      <td id=\"T_8a133_row1_col0\" class=\"data row1 col0\" >9.2571</td>\n",
       "      <td id=\"T_8a133_row1_col1\" class=\"data row1 col1\" >2.6517</td>\n",
       "      <td id=\"T_8a133_row1_col2\" class=\"data row1 col2\" >20.9813</td>\n",
       "      <td id=\"T_8a133_row1_col3\" class=\"data row1 col3\" >50.6679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a133_level0_row2\" class=\"row_heading level0 row2\" >M3</th>\n",
       "      <td id=\"T_8a133_row2_col0\" class=\"data row2 col0\" >6.2107</td>\n",
       "      <td id=\"T_8a133_row2_col1\" class=\"data row2 col1\" >0.6222</td>\n",
       "      <td id=\"T_8a133_row2_col2\" class=\"data row2 col2\" >9.4313</td>\n",
       "      <td id=\"T_8a133_row2_col3\" class=\"data row2 col3\" >8.7810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24465b016d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.highlight_min(color=\"green\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdm2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
